\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{mwe}
%\usepackage{lingmacros}
%\usepackage{tree-dvips}
%\usepackage{blindtext}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage[inline]{enumitem}

\usepackage{tikz}

\begin{document}

\title{
	Project 3: Neural Transliteration
}
\author{
Gudjon Magnusson 
\and Irina Yakubinskaya 
\and Matthew Goldberg
}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Seq-to-seq model configuration}

\subsection{Q1}
\textit{
Describe the network architecture for the encoder, and for the decoder model: what kind of RNNs are used? What are the dimensions of the various layers? What are the non-linearity functions used? How is the attention computed?
}


\section{Training algorithm}

\subsection{Q2}

\paragraph{n\_iters} is the number of training iterations used to train the model. Each iteration trains trains the model on one randomly chosen example from the training data.

\paragraph{learning\_rate} is how much the weights are updated based on one example. Before the error gradient is subtracted from the weights, its multiplied by \textit{learning\_rate}. Slowing down the learning (with $learning\_rate < 1$) makes the process more stable and prevents one bad example from ruining good weights.


\subsection{Q3}

To choose values for \textit{learning\_rate} and \textit{n\_iter} we ran two experiments. 
First we trained the model with a a few different values for \textit{learning\_rate} and tracked the loss for each iteration. We would like to find a value that decays the loss quickly and appears stable over a large number of iterations.
Next we trained the model and tracked how the average edit distance on a small held out dataset changed after every 100 iterations. For this we fixed \textit{learning\_rate} to something that appeared reasonable, we choose 0.01. The goal is to see how long we can train the model before over-fitting. We expect to see the edit distance to get lower at first and then start to rise again at some point.

\begin{figure}[t!]
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/alpha_unstable.pdf}
        \caption{Learning curves for different $\alpha$}
        \label{fig_learning_rate}
    \end{subfigure}
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/learning_curve.pdf}
        \caption{Average edit distance}
        \label{fig_n_iter}
    \end{subfigure}
	\caption{Experiments with \textit{learning\_rate} and \textit{n\_iter}}
	\label{fig_train_param}
\end{figure}


\section{Understanding teacher\_forcing}

\subsection{Q4}

\textit{teacher\_forcing} is the probability of using the "teacher" for each training sample. If it is set to 1, the teacher is used on every sample.

When the teacher is used for training mistakes that the model makes are ignored. At each time step, if the model makes a mistake, it contributes to loss but the model prediction is replaced the with the correct letter. The training moves to the next time step as if no mistake was made.

If the teacher is used too much it can lead to an unstable model that learns how to create good looking outputs rather than good transliterations. I.e its better to get the correct transliteration with one spelling mistake, than the wrong word perfectly spelled.

\subsection{Q5}
 
With higher values of \textit{teacher\_forcing} the loss decays faster during training. This can be seen in figure \ref{fig_teacher}, which shows the learning curve for 3 different values of \textit{teacher\_forcing}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{img/learning_curve.pdf}
    \caption{Learning curves for different values of \textit{teacher\_forcing}}
    \label{fig_teacher}
\end{figure}

\section{Impact of attention mechanism}

\subsection{Q6}
\textit{
Based on what we have learned in class, formulate a hypothesis about why the attention model is useful to model transliteration.	
}

\subsection{Q7}
\textit{
Update the implementation you have been given to use a sequence-to-sequence model without attention.  This will require modifying the code in transliterate.py to use DecoderRNN instead of AttnDecoderRNN.  Submit the modified code in a file named noattention.py
}

\subsection{Q8}
\textit{
Evaluate whether your hypothesis holds by comparing the behavior of the sequence-to-sequence model with and without attention empirically, at training and test time.
}

\section{Something new}

\subsection{Q9}
\textit{Briefly explain what you did}

\subsection{Q10}
\textit{Design an experiment to test whether your solution successfully addresses the problem}

\subsection{Q11}
\textit{}


\end{document}